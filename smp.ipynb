{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6a12fa50-7cd5-441f-8d2b-9af484c2c694",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "ad73196f-18ea-4f61-91d3-369dba3e2aee",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]       \n",
      "Get:3 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [25.8 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [844 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [994 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [1592 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]        \n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [29.4 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2017 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1063 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1136 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [25.5 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [50.8 kB]\n",
      "Fetched 21.2 MB in 2s (9477 kB/s)                            \n",
      "Reading package lists... Done\n",
      "^Cading package lists... 61%\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  dbus fontconfig fontconfig-config fonts-dejavu-core i965-va-driver\n",
      "  intel-media-va-driver libaacs0 libaom0 libapparmor1 libass9 libasyncns0\n",
      "  libavc1394-0 libavcodec58 libavdevice58 libavfilter7 libavformat58\n",
      "  libavresample4 libavutil56 libbdplus0 libbluray2 libbs2b0 libcaca0\n",
      "  libcairo-gobject2 libcairo2 libcdio-cdda2 libcdio-paranoia2 libcdio18\n",
      "  libchromaprint1 libcodec2-0.9 libdatrie1 libdbus-1-3 libdc1394-22\n",
      "  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1\n",
      "  libdrm2 libelf1 libfftw3-double3 libflite1 libfontconfig1 libfreetype6\n",
      "  libfribidi0 libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common\n",
      "  libgl1 libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libgme0\n",
      "  libgraphite2-3 libharfbuzz0b libice6 libicu66 libiec61883-0 libigdgmm11\n",
      "  libjack-jackd2-0 libjbig0 liblilv-0-0 libllvm12 libmp3lame0 libmpg123-0\n",
      "  libmysofa1 libnorm1 libopenal-data libopenal1 libopenjp2-7 libopenmpt0\n",
      "  libopus0 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0\n",
      "  libpgm-5.2-0 libpixman-1-0 libpostproc55 libpulse0 libraw1394-11 librsvg2-2\n",
      "  librsvg2-common librubberband2 libsamplerate0 libsdl2-2.0-0\n",
      "  libsensors-config libsensors5 libserd-0-0 libshine3 libslang2 libsndio7.0\n",
      "  libsodium23 libsord-0-0 libsoxr0 libspeex1 libsratom-0-0 libssh-gcrypt-4\n",
      "  libswresample3 libswscale5 libthai-data libthai0 libtheora0 libtiff5\n",
      "  libtwolame0 libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau1\n",
      "  libvidstab1.1 libvpx6 libvulkan1 libwayland-client0 libwayland-cursor0\n",
      "  libwayland-egl1 libwebp6 libwebpmux3 libwrap0 libx11-6 libx11-data\n",
      "  libx11-xcb1 libx264-155 libx265-179 libxau6 libxcb-dri2-0 libxcb-dri3-0\n",
      "  libxcb-glx0 libxcb-present0 libxcb-randr0 libxcb-render0 libxcb-shape0\n",
      "  libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1 libxcursor1 libxdmcp6\n",
      "  libxfixes3 libxi6 libxinerama1 libxkbcommon0 libxml2 libxrandr2 libxrender1\n",
      "  libxshmfence1 libxss1 libxv1 libxvidcore4 libxxf86vm1 libzmq5 libzvbi-common\n",
      "  libzvbi0 mesa-va-drivers mesa-vdpau-drivers mesa-vulkan-drivers\n",
      "  ocl-icd-libopencl1 shared-mime-info tzdata ucf va-driver-all\n",
      "  vdpau-driver-all x11-common xkb-data\n",
      "Suggested packages:\n",
      "  default-dbus-session-bus | dbus-session-bus ffmpeg-doc\n",
      "  i965-va-driver-shaders libbluray-bdj libfftw3-bin libfftw3-dev jackd2\n",
      "  libportaudio2 opus-tools pciutils pulseaudio libraw1394-doc librsvg2-bin\n",
      "  lm-sensors serdi sndiod sordi speex opencl-icd libvdpau-va-gl1\n",
      "  nvidia-vdpau-driver nvidia-legacy-340xx-vdpau-driver\n",
      "  nvidia-legacy-304xx-vdpau-driver\n",
      "The following NEW packages will be installed:\n",
      "  dbus ffmpeg fontconfig fontconfig-config fonts-dejavu-core i965-va-driver\n",
      "  intel-media-va-driver libaacs0 libaom0 libapparmor1 libass9 libasyncns0\n",
      "  libavc1394-0 libavcodec58 libavdevice58 libavfilter7 libavformat58\n",
      "  libavresample4 libavutil56 libbdplus0 libbluray2 libbs2b0 libcaca0\n",
      "  libcairo-gobject2 libcairo2 libcdio-cdda2 libcdio-paranoia2 libcdio18\n",
      "  libchromaprint1 libcodec2-0.9 libdatrie1 libdbus-1-3 libdc1394-22\n",
      "  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1\n",
      "  libdrm2 libelf1 libfftw3-double3 libflite1 libfontconfig1 libfreetype6\n",
      "  libfribidi0 libgdk-pixbuf2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common\n",
      "  libgl1 libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libgme0\n",
      "  libgraphite2-3 libharfbuzz0b libice6 libicu66 libiec61883-0 libigdgmm11\n",
      "  libjack-jackd2-0 libjbig0 liblilv-0-0 libllvm12 libmp3lame0 libmpg123-0\n",
      "  libmysofa1 libnorm1 libopenal-data libopenal1 libopenjp2-7 libopenmpt0\n",
      "  libopus0 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0\n",
      "  libpgm-5.2-0 libpixman-1-0 libpostproc55 libpulse0 libraw1394-11 librsvg2-2\n",
      "  librsvg2-common librubberband2 libsamplerate0 libsdl2-2.0-0\n",
      "  libsensors-config libsensors5 libserd-0-0 libshine3 libslang2 libsm6\n",
      "  libsndio7.0 libsodium23 libsord-0-0 libsoxr0 libspeex1 libsratom-0-0\n",
      "  libssh-gcrypt-4 libswresample3 libswscale5 libthai-data libthai0 libtheora0\n",
      "  libtiff5 libtwolame0 libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau1\n",
      "  libvidstab1.1 libvpx6 libvulkan1 libwayland-client0 libwayland-cursor0\n",
      "  libwayland-egl1 libwebp6 libwebpmux3 libwrap0 libx11-6 libx11-data\n",
      "  libx11-xcb1 libx264-155 libx265-179 libxau6 libxcb-dri2-0 libxcb-dri3-0\n",
      "  libxcb-glx0 libxcb-present0 libxcb-randr0 libxcb-render0 libxcb-shape0\n",
      "  libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1 libxcursor1 libxdmcp6\n",
      "  libxext6 libxfixes3 libxi6 libxinerama1 libxkbcommon0 libxml2 libxrandr2\n",
      "  libxrender1 libxshmfence1 libxss1 libxv1 libxvidcore4 libxxf86vm1 libzmq5\n",
      "  libzvbi-common libzvbi0 mesa-va-drivers mesa-vdpau-drivers\n",
      "  mesa-vulkan-drivers ocl-icd-libopencl1 shared-mime-info tzdata ucf\n",
      "  va-driver-all vdpau-driver-all x11-common xkb-data\n",
      "0 upgraded, 168 newly installed, 0 to remove and 46 not upgraded.\n",
      "Need to get 105 MB of archives.\n",
      "After this operation, 821 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libapparmor1 amd64 2.13.3-7ubuntu5.1 [34.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdbus-1-3 amd64 1.12.16-2ubuntu2.1 [179 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 dbus amd64 1.12.16-2ubuntu2.1 [151 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libelf1 amd64 0.176-1.1build1 [44.0 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libfribidi0 amd64 1.0.8-2 [23.8 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 tzdata all 2021e-0ubuntu0.20.04 [295 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libicu66 amd64 66.1-2ubuntu2.1 [8515 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libslang2 amd64 2.3.2-4 [429 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libsodium23 amd64 1.0.18-1 [150 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libxml2 amd64 2.9.10+dfsg-5ubuntu0.20.04.1 [640 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 shared-mime-info amd64 1.15-1 [430 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 ucf all 3.0038+nmu1 [51.6 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 xkb-data all 2.29-2 [349 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-common all 2.4.107-8ubuntu1~20.04.1 [5408 B]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm2 amd64 2.4.107-8ubuntu1~20.04.1 [34.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 libusb-1.0-0 amd64 2:1.0.23-2build1 [46.5 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 libxau6 amd64 1:1.0.9-0ubuntu1 [7488 B]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 libxdmcp6 amd64 1:1.1.3-0ubuntu1 [10.6 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb1 amd64 1.14-2 [44.7 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-data all 2:1.6.9-2ubuntu1.2 [113 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-6 amd64 2:1.6.9-2ubuntu1.2 [575 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libxext6 amd64 2:1.3.4-0ubuntu1 [29.1 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu focal/universe amd64 libaom0 amd64 1.0.0.errata1-3build1 [1160 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu focal/universe amd64 libva2 amd64 2.7.0-2 [53.5 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu focal/universe amd64 libva-drm2 amd64 2.7.0-2 [7044 B]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfixes3 amd64 1:5.0.3-2 [10.9 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu focal/universe amd64 libva-x11-2 amd64 2.7.0-2 [11.9 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu focal/main amd64 libvdpau1 amd64 1.3-1ubuntu2 [25.6 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu focal/main amd64 ocl-icd-libopencl1 amd64 2.2.11-1ubuntu1 [30.3 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavutil56 amd64 7:4.2.4-1ubuntu0.1 [241 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libfreetype6 amd64 2.10.1-2ubuntu0.1 [341 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-dejavu-core all 2.37-1 [1041 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu focal/main amd64 fontconfig-config all 2.13.1-2ubuntu3 [28.8 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontconfig1 amd64 2.13.1-2ubuntu3 [114 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu focal/main amd64 libpixman-1-0 amd64 0.38.4-0ubuntu1 [227 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-render0 amd64 1.14-2 [14.8 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-shm0 amd64 1.14-2 [5584 B]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu focal/main amd64 libxrender1 amd64 1:0.9.10-1 [18.7 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu focal/main amd64 libcairo2 amd64 1.16.0-4ubuntu1 [583 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu focal/universe amd64 libcodec2-0.9 amd64 0.9.2-2 [7886 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu focal/main amd64 libmp3lame0 amd64 3.100-3 [133 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libopenjp2-7 amd64 2.3.1-1ubuntu4.20.04.1 [141 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu focal/main amd64 libopus0 amd64 1.3.1-0ubuntu1 [191 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu focal/main amd64 libcairo-gobject2 amd64 1.16.0-4ubuntu1 [17.2 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu focal/main amd64 libjbig0 amd64 2.1-3.1build1 [26.7 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwebp6 amd64 0.6.1-2ubuntu0.20.04.1 [185 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libtiff5 amd64 4.1.0+git191117-2ubuntu0.20.04.2 [162 kB]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgdk-pixbuf2.0-common all 2.40.0+dfsg-3ubuntu0.2 [4652 B]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgdk-pixbuf2.0-0 amd64 2.40.0+dfsg-3ubuntu0.2 [168 kB]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu focal/main amd64 fontconfig amd64 2.13.1-2ubuntu3 [171 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu focal/main amd64 libgraphite2-3 amd64 1.3.13-11build1 [73.5 kB]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu focal/main amd64 libharfbuzz0b amd64 2.6.4-1ubuntu4 [391 kB]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu focal/main amd64 libthai-data all 0.1.28-3 [134 kB]\n",
      "Get:54 http://archive.ubuntu.com/ubuntu focal/main amd64 libdatrie1 amd64 0.2.12-3 [18.7 kB]\n",
      "Get:55 http://archive.ubuntu.com/ubuntu focal/main amd64 libthai0 amd64 0.1.28-3 [18.1 kB]\n",
      "Get:56 http://archive.ubuntu.com/ubuntu focal/main amd64 libpango-1.0-0 amd64 1.44.7-2ubuntu4 [162 kB]\n",
      "Get:57 http://archive.ubuntu.com/ubuntu focal/main amd64 libpangoft2-1.0-0 amd64 1.44.7-2ubuntu4 [34.9 kB]\n",
      "Get:58 http://archive.ubuntu.com/ubuntu focal/main amd64 libpangocairo-1.0-0 amd64 1.44.7-2ubuntu4 [24.8 kB]\n",
      "Get:59 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 librsvg2-2 amd64 2.48.9-1ubuntu0.20.04.1 [2253 kB]\n",
      "Get:60 http://archive.ubuntu.com/ubuntu focal/universe amd64 libshine3 amd64 3.1.1-2 [23.2 kB]\n",
      "Get:61 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libspeex1 amd64 1.2~rc1.2-1.1ubuntu1.20.04.1 [53.2 kB]\n",
      "Get:62 http://archive.ubuntu.com/ubuntu focal/main amd64 libsoxr0 amd64 0.1.3-2build1 [78.0 kB]\n",
      "Get:63 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libswresample3 amd64 7:4.2.4-1ubuntu0.1 [57.1 kB]\n",
      "Get:64 http://archive.ubuntu.com/ubuntu focal/main amd64 libtheora0 amd64 1.1.1+dfsg.1-15ubuntu2 [162 kB]\n",
      "Get:65 http://archive.ubuntu.com/ubuntu focal/main amd64 libtwolame0 amd64 0.4.0-2 [47.6 kB]\n",
      "Get:66 http://archive.ubuntu.com/ubuntu focal/main amd64 libvpx6 amd64 1.8.2-1build1 [820 kB]\n",
      "Get:67 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwebpmux3 amd64 0.6.1-2ubuntu0.20.04.1 [19.5 kB]\n",
      "Get:68 http://archive.ubuntu.com/ubuntu focal/universe amd64 libx264-155 amd64 2:0.155.2917+git0a84d98-2 [521 kB]\n",
      "Get:69 http://archive.ubuntu.com/ubuntu focal/universe amd64 libx265-179 amd64 3.2.1-1build1 [1060 kB]\n",
      "Get:70 http://archive.ubuntu.com/ubuntu focal/universe amd64 libxvidcore4 amd64 2:1.3.7-1 [201 kB]\n",
      "Get:71 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzvbi-common all 0.2.35-17 [32.5 kB]\n",
      "Get:72 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzvbi0 amd64 0.2.35-17 [237 kB]\n",
      "Get:73 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavcodec58 amd64 7:4.2.4-1ubuntu0.1 [4876 kB]\n",
      "Get:74 http://archive.ubuntu.com/ubuntu focal/main amd64 libraw1394-11 amd64 2.1.2-1 [30.7 kB]\n",
      "Get:75 http://archive.ubuntu.com/ubuntu focal/main amd64 libavc1394-0 amd64 0.5.4-5 [16.2 kB]\n",
      "Get:76 http://archive.ubuntu.com/ubuntu focal/universe amd64 libass9 amd64 1:0.14.0-2 [88.0 kB]\n",
      "Get:77 http://archive.ubuntu.com/ubuntu focal/universe amd64 libbluray2 amd64 1:1.2.0-1 [138 kB]\n",
      "Get:78 http://archive.ubuntu.com/ubuntu focal/universe amd64 libchromaprint1 amd64 1.4.3-3build1 [37.6 kB]\n",
      "Get:79 http://archive.ubuntu.com/ubuntu focal/universe amd64 libgme0 amd64 0.6.2-1build1 [123 kB]\n",
      "Get:80 http://archive.ubuntu.com/ubuntu focal/main amd64 libmpg123-0 amd64 1.25.13-1 [124 kB]\n",
      "Get:81 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenmpt0 amd64 0.4.11-1build1 [599 kB]\n",
      "Get:82 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libssh-gcrypt-4 amd64 0.9.3-2ubuntu2.2 [202 kB]\n",
      "Get:83 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavformat58 amd64 7:4.2.4-1ubuntu0.1 [981 kB]\n",
      "Get:84 http://archive.ubuntu.com/ubuntu focal/universe amd64 libbs2b0 amd64 3.1.0+dfsg-2.2build1 [10.2 kB]\n",
      "Get:85 http://archive.ubuntu.com/ubuntu focal/universe amd64 libflite1 amd64 2.1-release-3 [12.8 MB]\n",
      "Get:86 http://archive.ubuntu.com/ubuntu focal/universe amd64 libserd-0-0 amd64 0.30.2-1 [46.6 kB]\n",
      "Get:87 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsord-0-0 amd64 0.16.4-1 [19.5 kB]\n",
      "Get:88 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsratom-0-0 amd64 0.6.4-1 [16.9 kB]\n",
      "Get:89 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 liblilv-0-0 amd64 0.24.6-1ubuntu0.1 [40.6 kB]\n",
      "Get:90 http://archive.ubuntu.com/ubuntu focal/universe amd64 libmysofa1 amd64 1.0~dfsg0-1 [39.2 kB]\n",
      "Get:91 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libpostproc55 amd64 7:4.2.4-1ubuntu0.1 [55.3 kB]\n",
      "Get:92 http://archive.ubuntu.com/ubuntu focal/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu1 [728 kB]\n",
      "Get:93 http://archive.ubuntu.com/ubuntu focal/main amd64 libsamplerate0 amd64 0.1.9-2 [939 kB]\n",
      "Get:94 http://archive.ubuntu.com/ubuntu focal/universe amd64 librubberband2 amd64 1.8.2-1build1 [89.4 kB]\n",
      "Get:95 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libswscale5 amd64 7:4.2.4-1ubuntu0.1 [156 kB]\n",
      "Get:96 http://archive.ubuntu.com/ubuntu focal/universe amd64 libvidstab1.1 amd64 1.1.0-2 [35.0 kB]\n",
      "Get:97 http://archive.ubuntu.com/ubuntu focal/universe amd64 libnorm1 amd64 1.5.8+dfsg2-2build1 [290 kB]\n",
      "Get:98 http://archive.ubuntu.com/ubuntu focal/universe amd64 libpgm-5.2-0 amd64 5.2.122~dfsg-3ubuntu1 [158 kB]\n",
      "Get:99 http://archive.ubuntu.com/ubuntu focal/universe amd64 libzmq5 amd64 4.3.2-2ubuntu1 [242 kB]\n",
      "Get:100 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavfilter7 amd64 7:4.2.4-1ubuntu0.1 [1084 kB]\n",
      "Get:101 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libcaca0 amd64 0.99.beta19-2.1ubuntu1.20.04.2 [203 kB]\n",
      "Get:102 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio18 amd64 2.0.0-2 [58.6 kB]\n",
      "Get:103 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio-cdda2 amd64 10.2+2.0.0-1 [17.6 kB]\n",
      "Get:104 http://archive.ubuntu.com/ubuntu focal/main amd64 libcdio-paranoia2 amd64 10.2+2.0.0-1 [16.2 kB]\n",
      "Get:105 http://archive.ubuntu.com/ubuntu focal/universe amd64 libdc1394-22 amd64 2.2.5-2.1 [79.6 kB]\n",
      "Get:106 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglvnd0 amd64 1.3.2-1~ubuntu0.20.04.1 [51.4 kB]\n",
      "Get:107 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglapi-mesa amd64 21.2.6-0ubuntu0.1~20.04.1 [27.3 kB]\n",
      "Get:108 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-xcb1 amd64 2:1.6.9-2ubuntu1.2 [9372 B]\n",
      "Get:109 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-dri2-0 amd64 1.14-2 [6920 B]\n",
      "Get:110 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-dri3-0 amd64 1.14-2 [6552 B]\n",
      "Get:111 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-glx0 amd64 1.14-2 [22.1 kB]\n",
      "Get:112 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-present0 amd64 1.14-2 [5560 B]\n",
      "Get:113 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-sync1 amd64 1.14-2 [8884 B]\n",
      "Get:114 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-xfixes0 amd64 1.14-2 [9296 B]\n",
      "Get:115 http://archive.ubuntu.com/ubuntu focal/main amd64 libxshmfence1 amd64 1.3-1 [5028 B]\n",
      "Get:116 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86vm1 amd64 1:1.1.4-1build1 [10.2 kB]\n",
      "Get:117 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-amdgpu1 amd64 2.4.107-8ubuntu1~20.04.1 [18.4 kB]\n",
      "Get:118 http://archive.ubuntu.com/ubuntu focal/main amd64 libpciaccess0 amd64 0.16-0ubuntu1 [17.9 kB]\n",
      "Get:119 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-intel1 amd64 2.4.107-8ubuntu1~20.04.1 [60.3 kB]\n",
      "Get:120 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-nouveau2 amd64 2.4.107-8ubuntu1~20.04.1 [16.6 kB]\n",
      "Get:121 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-radeon1 amd64 2.4.107-8ubuntu1~20.04.1 [19.7 kB]\n",
      "Get:122 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libllvm12 amd64 1:12.0.0-3ubuntu1~20.04.4 [18.8 MB]\n",
      "Get:123 http://archive.ubuntu.com/ubuntu focal/main amd64 libsensors-config all 1:3.6.0-2ubuntu1 [6092 B]\n",
      "Get:124 http://archive.ubuntu.com/ubuntu focal/main amd64 libsensors5 amd64 1:3.6.0-2ubuntu1 [27.4 kB]\n",
      "Get:125 http://archive.ubuntu.com/ubuntu focal/main amd64 libvulkan1 amd64 1.2.131.2-1 [93.3 kB]\n",
      "Get:126 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgl1-mesa-dri amd64 21.2.6-0ubuntu0.1~20.04.1 [11.0 MB]\n",
      "Get:127 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglx-mesa0 amd64 21.2.6-0ubuntu0.1~20.04.1 [137 kB]\n",
      "Get:128 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglx0 amd64 1.3.2-1~ubuntu0.20.04.1 [32.6 kB]\n",
      "Get:129 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgl1 amd64 1.3.2-1~ubuntu0.20.04.1 [86.9 kB]\n",
      "Get:130 http://archive.ubuntu.com/ubuntu focal/main amd64 libiec61883-0 amd64 1.2.0-3 [24.3 kB]\n",
      "Get:131 http://archive.ubuntu.com/ubuntu focal/main amd64 libjack-jackd2-0 amd64 1.9.12~dfsg-2ubuntu2 [267 kB]\n",
      "Get:132 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenal-data all 1:1.19.1-1 [162 kB]\n",
      "Get:133 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsndio7.0 amd64 1.5.0-3 [24.5 kB]\n",
      "Get:134 http://archive.ubuntu.com/ubuntu focal/universe amd64 libopenal1 amd64 1:1.19.1-1 [492 kB]\n",
      "Get:135 http://archive.ubuntu.com/ubuntu focal/main amd64 libasyncns0 amd64 0.8-6 [12.1 kB]\n",
      "Get:136 http://archive.ubuntu.com/ubuntu focal/main amd64 libwrap0 amd64 7.6.q-30 [46.3 kB]\n",
      "Get:137 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpulse0 amd64 1:13.99.1-1ubuntu3.13 [262 kB]\n",
      "Get:138 http://archive.ubuntu.com/ubuntu focal/main amd64 libwayland-client0 amd64 1.18.0-1 [23.9 kB]\n",
      "Get:139 http://archive.ubuntu.com/ubuntu focal/main amd64 libwayland-cursor0 amd64 1.18.0-1 [10.3 kB]\n",
      "Get:140 http://archive.ubuntu.com/ubuntu focal/main amd64 libwayland-egl1 amd64 1.18.0-1 [5692 B]\n",
      "Get:141 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcursor1 amd64 1:1.2.0-2 [20.1 kB]\n",
      "Get:142 http://archive.ubuntu.com/ubuntu focal/main amd64 libxi6 amd64 2:1.7.10-0ubuntu1 [29.9 kB]\n",
      "Get:143 http://archive.ubuntu.com/ubuntu focal/main amd64 libxinerama1 amd64 2:1.1.4-2 [6904 B]\n",
      "Get:144 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbcommon0 amd64 0.10.0-1 [98.4 kB]\n",
      "Get:145 http://archive.ubuntu.com/ubuntu focal/main amd64 libxrandr2 amd64 2:1.5.2-0ubuntu1 [18.5 kB]\n",
      "Get:146 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-common all 1:7.7+19ubuntu14 [22.3 kB]\n",
      "Get:147 http://archive.ubuntu.com/ubuntu focal/main amd64 libxss1 amd64 1:1.2.3-1 [8140 B]\n",
      "Get:148 http://archive.ubuntu.com/ubuntu focal/universe amd64 libsdl2-2.0-0 amd64 2.0.10+dfsg1-3 [407 kB]\n",
      "Get:149 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-shape0 amd64 1.14-2 [5928 B]\n",
      "Get:150 http://archive.ubuntu.com/ubuntu focal/main amd64 libxv1 amd64 2:1.0.11-1 [10.7 kB]\n",
      "Get:151 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavdevice58 amd64 7:4.2.4-1ubuntu0.1 [74.3 kB]\n",
      "Get:152 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 libavresample4 amd64 7:4.2.4-1ubuntu0.1 [54.2 kB]\n",
      "Get:153 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 ffmpeg amd64 7:4.2.4-1ubuntu0.1 [1453 kB]\n",
      "Get:154 http://archive.ubuntu.com/ubuntu focal/universe amd64 libigdgmm11 amd64 20.1.1+ds1-1 [111 kB]\n",
      "Get:155 http://archive.ubuntu.com/ubuntu focal/universe amd64 intel-media-va-driver amd64 20.1.1+dfsg1-1 [1764 kB]\n",
      "Get:156 http://archive.ubuntu.com/ubuntu focal/universe amd64 libaacs0 amd64 0.9.0-2 [50.1 kB]\n",
      "Get:157 http://archive.ubuntu.com/ubuntu focal/universe amd64 libbdplus0 amd64 0.1.2-3 [47.3 kB]\n",
      "Get:158 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgdk-pixbuf2.0-bin amd64 2.40.0+dfsg-3ubuntu0.2 [14.1 kB]\n",
      "Get:159 http://archive.ubuntu.com/ubuntu focal/main amd64 libice6 amd64 2:1.0.10-0ubuntu1 [41.0 kB]\n",
      "Get:160 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 librsvg2-common amd64 2.48.9-1ubuntu0.20.04.1 [9212 B]\n",
      "Get:161 http://archive.ubuntu.com/ubuntu focal/main amd64 libsm6 amd64 2:1.2.3-1 [16.1 kB]\n",
      "Get:162 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-randr0 amd64 1.14-2 [16.3 kB]\n",
      "Get:163 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 mesa-va-drivers amd64 21.2.6-0ubuntu0.1~20.04.1 [2968 kB]\n",
      "Get:164 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 mesa-vdpau-drivers amd64 21.2.6-0ubuntu0.1~20.04.1 [3089 kB]\n",
      "Get:165 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 mesa-vulkan-drivers amd64 21.2.6-0ubuntu0.1~20.04.1 [5784 kB]\n",
      "Get:166 http://archive.ubuntu.com/ubuntu focal/universe amd64 i965-va-driver amd64 2.4.0-0ubuntu1 [924 kB]\n",
      "Get:167 http://archive.ubuntu.com/ubuntu focal/universe amd64 va-driver-all amd64 2.7.0-2 [4020 B]\n",
      "Get:168 http://archive.ubuntu.com/ubuntu focal/main amd64 vdpau-driver-all amd64 1.3-1ubuntu2 [4596 B]\n",
      "Fetched 105 MB in 5s (21.7 MB/s)              \n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 168.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Extracting templates from packages: 100%\n",
      "Preconfiguring packages ...\n",
      "Configuring tzdata\n",
      "------------------\n",
      "\n",
      "Please select the geographic area in which you live. Subsequent configuration\n",
      "questions will narrow this down by presenting a list of cities, representing\n",
      "the time zones in which they are located.\n",
      "\n",
      "  1. Africa      4. Australia  7. Atlantic  10. Pacific  13. Etc\n",
      "  2. America     5. Arctic     8. Europe    11. SystemV\n",
      "  3. Antarctica  6. Asia       9. Indian    12. US\n",
      "\u001b[4mGeographic area: \u001b[m\u001b[1m"
     ]
    }
   ],
   "source": [
    "# Install required libs\n",
    "\n",
    "### PAPERSPACE ONLY ###\n",
    "!apt-get update && ln -snf /usr/share/zoneinfo/Europe/Berlin /etc/localtime && DEBIAN_FRONTEND=noninteractive apt-get install -y tzdata\n",
    "!apt-get install ffmpeg libsm6 libxext6 -y \n",
    "### PAPERSPACE ONLY END ###\n",
    "\n",
    "!python -m pip install --user tensorboard numpy matplotlib ipython ipykernel jupyter segmentation-models-pytorch albumentations opencv-python tqdm natsort scikit-image ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "937c2067-794b-4e23-8cd6-9fa33350f19c",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import VOCSegmentation\n",
    "import os\n",
    "import numbers\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "from natsort import natsorted\n",
    "from functools import reduce\n",
    "from skimage import io\n",
    "import albumentations as albu\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b286ff3d-19be-4033-8cd2-8a8b04df14da",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "log_dir_name = writer.get_logdir()\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_WORKERS = 8 if torch.cuda.is_available() else 0\n",
    "print(\"Using {} device\".format(DEVICE))\n",
    "print(\"Using {} workers\".format(NUM_WORKERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "cfb01df7-8c39-4025-a452-a1aad9808949",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### MHP dataset link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8732b2aa-a675-4de6-b7c4-b8f5f5f4aa46",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "# Download LV-MHP-v2 manually and extract to data dir\n",
    "# https://drive.google.com/file/d/1YVBGMru0dlwB8zu1OoErOazZoc8ISSJn/\n",
    "\n",
    "# Voc will be downloaded later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "628cabce-91f2-4249-809f-e709bba9195f",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7cd6d359-349d-4726-9561-a2c1b4807b49",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def verify_image(img_file):\n",
    "    try:\n",
    "        img = io.imread(img_file)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_mask_fp_infos(mask_fp):\n",
    "    id, num_persons, curr_person = os.path.basename(mask_fp).split(\".\")[0].split(\"_\")\n",
    "    return int(id), int(num_persons), int(curr_person)\n",
    "\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5bceaacd-3463-47cd-8529-790758966b7b",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "# Dataloaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "912d83c2-bd4c-4ed7-8d3b-980339313146",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "MHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8650bc1c-1026-4fa5-af44-647343d26150",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \"\"\"MHP v2 Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    CLASS_LABELS = [\n",
    "        \"Background\", \"Cap/hat\",\"Helmet\", \"Face\", \"Hair\", \"Left-arm\", \"Right-arm\", \"Left-hand\", \"Right-hand\", \"Protector\", \n",
    "        \"Bikini/bra\", \"Jacket/windbreaker/hoodie\", \"Tee-shirt\", \"Polo-shirt\", \"Sweater\", \"Singlet\", \"Torso-skin\", \n",
    "        \"Pants\", \"Shorts/swim-shorts\", \"Skirt\", \"Stockings\", \"Socks\", \"Left-boot\", \"Right-boot\", \"Left-shoe\",\n",
    "        \"Right-shoe\", \"Left-highheel\", \"Right-highheel\", \"Left-sandal\", \"Right-sandal\", \"Left-leg\", \"Right-leg\",\n",
    "        \"Left-foot\", \"Right-foot\", \"Coat\", \"Dress\", \"Robe\", \"Jumpsuit\" , \"Other-full-body-clothes\" , \"Headwear\",\n",
    "        \"Backpack\", \"Ball\", \"Bats\", \"Belt\", \"Bottle\", \"Carrybag\", \"Cases\", \"Sunglasses\", \"Eyewear\", \"Glove\",\n",
    "        \"Scarf\", \"Umbrella\",\" Wallet/purse\", \"Watch\", \"Wristband\", \"Tie\",\" Other-accessary\", \n",
    "        \"Other-upper-body-clothes\", \"Other-lower-body-clothes\"\n",
    "        ]\n",
    "\n",
    "    def __init__(self, size, classes=None, augmentation=None, preprocessing=None):\n",
    "        images_dir = \"data/LV-MHP-v2/train/images/\"\n",
    "        masks_dir = \"data/LV-MHP-v2/train/parsing_annos/\"\n",
    "        self.images_ids = natsorted(os.listdir(images_dir))[0:size]\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.images_ids]\n",
    "        self.masks_ids = natsorted(os.listdir(masks_dir))\n",
    "        self.masks_fps = [os.path.join(masks_dir, mask_id) for mask_id in self.masks_ids]\n",
    "    \n",
    "        # convert str names to class values on masks\n",
    "        self.class_indices = [self.CLASS_LABELS.index(cls) for cls in classes]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if verify_image(self.images_fps[i]):\n",
    "            # read image\n",
    "            image = cv2.imread(self.images_fps[i])\n",
    "        else:\n",
    "            image = cv2.imread(self.images_fps[i-1])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # combine mask files\n",
    "        mask_files_per_image = []\n",
    "        for el in self.masks_fps:\n",
    "            mask_id = int(get_mask_fp_infos(el)[0]) \n",
    "            img_id = int(self.images_ids[i].split(\".\")[0])\n",
    "            if(mask_id == img_id):\n",
    "                mask_files_per_image.append(el)\n",
    "        \n",
    "        mask_files = []\n",
    "        for file in mask_files_per_image:\n",
    "            mask_file = cv2.imread(file)\n",
    "            if mask_file.ndim == 3:\n",
    "                mask_file = cv2.cvtColor(mask_file, cv2.COLOR_BGR2RGB)\n",
    "                mask_file = mask_file[:,:,0]\n",
    "                mask_files.append(mask_file)\n",
    "        # Create union of all mask files\n",
    "        combined_file = reduce(lambda array_a, array_b: array_a | array_b, mask_files)\n",
    "\n",
    "         # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(combined_file == label_index) for label_index in self.class_indices]\n",
    "        mask = reduce(lambda array_a, array_b: array_a | array_b, masks)\n",
    "        if self.class_indices == [0]:\n",
    "            mask = np.invert(mask)\n",
    "        mask = mask[:,:, np.newaxis]\n",
    "        mask = mask.astype('float')\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask, combined_file=combined_file)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "eb954368-aa6f-4f7c-984a-3e50b34c10f5",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(size=2000, classes=['Background'])\n",
    "\n",
    "example_image, example_mask = dataset[0] # get some sample\n",
    "\n",
    "visualize(\n",
    "    image=example_image, \n",
    "    mask=example_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "620375d4-8e00-4b1b-b2d2-9fa4aac4e9b9",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "VOC Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "811c0667-14ec-4241-a1d1-2327674d790c",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "VOC_CLASSES = [\n",
    "    \"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \n",
    "    \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \n",
    "    \"person\", \"potted plant\", \"sheep\", \"sofa\", \"train\", \"tv/monitor\",\n",
    "]\n",
    "\n",
    "VOC_COLORMAP = [\n",
    "    [0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0], [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128], \n",
    "    [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0], [64, 0, 128], [192, 0, 128], [64, 128, 128], \n",
    "    [192, 128, 128], [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0], [0, 64, 128],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2d6f1210-0d44-4127-88f8-727e4b0fa52f",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "class TransformedVOC(VOCSegmentation):\n",
    "    # def __init__(self, augmentation=None, preprocessing=None, classes=VOC_CLASSES):\n",
    "    def __init__(self, root, image_set, download=False,  augmentation=None, preprocessing=None):\n",
    "        super(TransformedVOC, self).__init__(root=root, image_set=image_set, download=download)\n",
    "        # self.classes = classes\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.remove_list = []\n",
    "\n",
    "    # @staticmethod\n",
    "    # def _convert_to_segmentation_mask(mask, labels):\n",
    "    #     height, width = mask.shape[:2]\n",
    "    #     segmentation_mask = np.zeros((height, width, len(labels)), dtype=np.float32)\n",
    "    #     for idx, label in enumerate(labels):\n",
    "    #         label_idx = VOC_CLASSES.index(label)\n",
    "    #         label_color = VOC_COLORMAP[label_idx]\n",
    "    #         segmentation_mask[:, :, idx] = np.all(mask == label_color, axis=-1).astype(float)\n",
    "    #     return segmentation_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # image = cv2.imread(self.images[idx])\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # mask = cv2.imread(self.masks[idx])\n",
    "        # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        # mask = self._convert_to_segmentation_mask(mask, self.classes)\n",
    "\n",
    "        image, mask = super(TransformedVOC, self).__getitem__(idx)\n",
    "        image = np.array(image)\n",
    "        mask = np.array(mask)\n",
    "        mask = mask.astype('float')\n",
    "        mask = np.where(mask==15, 1., 0.)\n",
    "        uniques = np.unique(mask)\n",
    "        if 1. not in uniques:\n",
    "            self.remove_list.append(idx)\n",
    "        mask = mask[:,:,np.newaxis]\n",
    "\n",
    "         # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4c22acbe-861f-4428-83f0-d5d7c4c9ab3b",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TransformedVOC(root=\"data/\", image_set=\"trainval\", download=False)\n",
    "\n",
    "example_image, example_mask = dataset[0] # get some sample\n",
    "\n",
    "visualize(\n",
    "    image=example_image, \n",
    "    mask=example_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "165d224a-119e-4eb1-a584-80bf98b002b4",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "VOC Orig Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "eca3824c-190c-41ac-b0ab-1729848632b4",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "class VOCOrig(VOCSegmentation):\n",
    "    def __init__(self, root, image_set,  augmentation=None, preprocessing=None, classes=VOC_CLASSES):\n",
    "        super(VOCOrig, self).__init__(root, image_set = image_set)\n",
    "        self.classes = classes\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        \n",
    "    @staticmethod\n",
    "    def _convert_to_segmentation_mask(mask, labels):\n",
    "        height, width = mask.shape[:2]\n",
    "        segmentation_mask = np.zeros((height, width, len(labels)), dtype=np.float32)\n",
    "        for idx, label in enumerate(labels):\n",
    "            label_idx = VOC_CLASSES.index(label)\n",
    "            label_color = VOC_COLORMAP[label_idx]\n",
    "            segmentation_mask[:, :, idx] = np.all(mask == label_color, axis=-1).astype(float)\n",
    "        return segmentation_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.images[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks[idx])\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = self._convert_to_segmentation_mask(mask, self.classes)\n",
    "\n",
    "         # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1bab846a-d1b9-411a-8b7e-959285c39a44",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "dataset = VOCOrig(root=\"data/\", image_set=\"trainval\")\n",
    "\n",
    "example_image, example_mask = dataset[0] # get some sample\n",
    "    \n",
    "visualize(\n",
    "    image=example_image, \n",
    "    mask0=example_mask[:,:,0],\n",
    "    mask1=example_mask[:,:,1],\n",
    "    mask2=example_mask[:,:,2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5e77d301-44ca-49d6-baf6-ab53e3991576",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9b908534-2d24-4c8c-8af3-850266361200",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " MHP Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a04d708c-5cb8-44fe-91f8-feba06414359",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "class HeadCrop(object):\n",
    "    \"\"\"Crops the given PIL Image around head region.\"\"\"\n",
    "\n",
    "    def __init__(self, size, offset):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.offset = offset\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        image = kwargs.get('image', None)\n",
    "        mask = kwargs.get('mask', None)\n",
    "        combined_file = kwargs.get('combined_file', None)\n",
    "        \n",
    "\n",
    "        # Extract head region\n",
    "        head_masks = [(combined_file == label_index) for label_index in [4, 3, 2, 39]]\n",
    "        head_mask = reduce(lambda array_a, array_b: array_a | array_b, head_masks)\n",
    "        # Get coordinates of first head pixel\n",
    "        first_head = np.where(head_mask == True)\n",
    "        row, col = first_head[0][0], first_head[1][0]\n",
    "        x_min = max(0, col - self.size[1] // 2)\n",
    "        y_min = max(0, row + self.offset - self.size[0] // 2)\n",
    "        x_max = x_min + self.size[1]\n",
    "        y_max = y_min + self.size[0]\n",
    "        cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "        cropped_mask = mask[y_min:y_max, x_min:x_max]\n",
    "        return {\"image\": cropped_image, \"mask\": cropped_mask}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "class CustomResize(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, **kwargs):\n",
    "        image = kwargs.get('image', None)\n",
    "        mask = kwargs.get('mask', None)\n",
    "        image = cv2.resize(image, (self.size, self.size), interpolation=cv2.INTER_NEAREST)\n",
    "        mask = cv2.resize(mask, (self.size, self.size), interpolation=cv2.INTER_NEAREST)\n",
    "        return {\"image\": image, \"mask\": mask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e23ae533-e2ff-473a-bbbb-b438cca17612",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        HeadCrop((200, 400), 100),\n",
    "        albu.Resize(IMG_SIZE,IMG_SIZE)\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    test_transform = [\n",
    "        HeadCrop((200, 400), 100),\n",
    "        albu.Resize(IMG_SIZE,IMG_SIZE)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d1194d75-78fd-4641-9744-67043d7f9f9b",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    augmentation=get_training_augmentation(),\n",
    "    size=2000, \n",
    "    classes=['Background'])\n",
    "\n",
    "example_image, example_mask = dataset[0] # get some sample\n",
    "\n",
    "visualize(\n",
    "    image=example_image, \n",
    "    mask=example_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "38b1ca13-895a-4683-b91f-ed83ed38c3fb",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "VOC Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5bd06a52-4bfc-4b74-8137-d4a4b8624e90",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation_voc():\n",
    "    train_transform = [\n",
    "        albu.Resize(IMG_SIZE,IMG_SIZE)\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation_voc():\n",
    "    test_transform = [\n",
    "        albu.Resize(IMG_SIZE,IMG_SIZE)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "87026c4d-117b-4884-85a9-70e8078174b1",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TransformedVOC(root=\"data/\", image_set=\"trainval\", download=False, augmentation=get_training_augmentation_voc())\n",
    "\n",
    "example_image, example_mask = dataset[0] # get some sample\n",
    "\n",
    "visualize(\n",
    "    image=example_image, \n",
    "    mask=example_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8e95a31f-b743-4a0f-b13c-4c0c174aa050",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "VOC Orig Augmentations Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "09fc4f0b-5156-480f-b788-f73d58211e43",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_voc_orig = VOCOrig(\n",
    "    root=\"data/\", \n",
    "    image_set=\"train\", \n",
    "    augmentation=get_training_augmentation_voc(), \n",
    "    )\n",
    "\n",
    "example_image, example_mask = train_dataset_voc_orig[0] # get some sample\n",
    "\n",
    "visualize(\n",
    "    image=example_image, \n",
    "    mask0=example_mask[:,:,0],\n",
    "    mask1=example_mask[:,:,1],\n",
    "    mask2=example_mask[:,:,2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8bbcf2d4-4156-4550-8b5d-c20b1ff50f5a",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### VOC Extended Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9903151c-3b5c-4cae-914e-cc52ff21ef50",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation_voc_ext():\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "\n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        albu.RandomCrop(height=200, width=200, always_apply=True),\n",
    "        albu.Resize(IMG_SIZE,IMG_SIZE),\n",
    "\n",
    "        albu.augmentations.transforms.GaussNoise(p=0.2),\n",
    "        albu.augmentations.geometric.transforms.Perspective(p=0.5),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.CLAHE(p=1),\n",
    "                albu.RandomBrightnessContrast(p=1),\n",
    "                albu.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.augmentations.transforms.Sharpen(p=1),\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomBrightnessContrast(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f6419992-e8c6-4234-815a-38e4332b00a4",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "373e6936-f9a5-4d13-88ee-0bf8a3219ce9",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "96c4b97e-4c9b-4830-8ad5-f98ffa08718a",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7af42c16-51b1-43c3-96ed-8ae0cb6a0e07",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "ENCODER = 'timm-mobilenetv3_large_100'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['Background']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "\n",
    "models = {}\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "models[\"mhp\"] = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "models[\"mhp\"].to(torch.device(DEVICE))\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "models[\"voc\"] = smp.DeepLabV3(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "models[\"voc\"].to(torch.device(DEVICE))\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "models[\"voc_orig\"] = smp.DeepLabV3(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(VOC_CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "models[\"voc_orig\"].to(torch.device(DEVICE))\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "models[\"voc_ext\"] = smp.DeepLabV3(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "models[\"voc_ext\"].to(torch.device(DEVICE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "81d28575-495d-4839-ae32-07de80cdc45d",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Load MHP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "3453d3c9-235e-439a-8a15-386c2d7f930c",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "full_dataset = Dataset(\n",
    "    #size=15403,\n",
    "    size=3641,\n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn), \n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "\n",
    "full_dataset_size = len(full_dataset)\n",
    "full_dataset_indices = list(range(full_dataset_size))\n",
    "\n",
    "# Shuffle\n",
    "np.random.shuffle(full_dataset_indices)\n",
    "# Rename for readabilty and limit to 3641\n",
    "random_indices = full_dataset_indices[0:3641]\n",
    "random_dataset = torch.utils.data.Subset(full_dataset, random_indices)\n",
    "\n",
    "\n",
    "# Create train (size=1464), valid (size=1449) and test (size=728) split.\n",
    "train_valid_dataset, test_dataset = torch.utils.data.random_split(random_dataset, [2913, 728])\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(train_valid_dataset, [1464, 1449])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d248345f-4d51-48e3-a094-006f113a49a6",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Load VOC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "61b27fff-f044-467b-bcc9-35d6024b10ed",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_voc = TransformedVOC(\n",
    "    root=\"data/\", \n",
    "    image_set=\"train\", \n",
    "    augmentation=get_training_augmentation_voc(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    )\n",
    "\n",
    "\n",
    "valid_dataset_voc = TransformedVOC(\n",
    "    root=\"data/\", \n",
    "    image_set=\"val\", \n",
    "    augmentation=get_validation_augmentation_voc(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn))\n",
    "\n",
    "\n",
    "train_loader_voc = DataLoader(train_dataset_voc, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_loader_voc = DataLoader(valid_dataset_voc, batch_size=16, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "679be7c3-756a-4af0-a616-a4eab5e578a5",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Load VOC Orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "0323c0ae-f6cf-4a81-8f50-a9310de90bc3",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_voc_orig = VOCOrig(\n",
    "    root=\"data/\", \n",
    "    image_set=\"train\", \n",
    "    augmentation=get_training_augmentation_voc(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    "    )\n",
    "\n",
    "valid_dataset_voc_orig = VOCOrig(\n",
    "    root=\"data/\", \n",
    "    image_set=\"val\", \n",
    "    augmentation=get_validation_augmentation_voc(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader_voc_orig = DataLoader(train_dataset_voc_orig, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_loader_voc_orig = DataLoader(valid_dataset_voc_orig, batch_size=16, shuffle=False, num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8a690c84-94a6-4bd9-8675-afac17b2cb61",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Load VOC Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b2e9a4f8-a672-48ee-aae5-ca64ae59d219",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "file = open('voc_ext_train_idxs.txt', 'r')\n",
    "idxs = [int(i) for i in file.read().splitlines()]\n",
    "\n",
    "# Train Dataset\n",
    "datasets = []\n",
    "for i in range(0,5):\n",
    "    dataset = TransformedVOC(root=\"data/\", image_set=\"train\", download=False, augmentation=get_training_augmentation_voc_ext(), preprocessing=get_preprocessing(preprocessing_fn))\n",
    "    dataset = torch.utils.data.Subset(dataset, idxs)\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "\n",
    "train_dataset_voc_ext_big = torch.utils.data.ConcatDataset(datasets)\n",
    "train_dataset_voc_ext = torch.utils.data.Subset(train_dataset_voc_ext_big, indices = range(0, 1464))\n",
    "\n",
    "# Valid Dataset\n",
    "valid_dataset_voc_ext = TransformedVOC(\n",
    "    root=\"data/\", \n",
    "    image_set=\"val\", \n",
    "    augmentation=get_validation_augmentation_voc(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader_voc_ext = DataLoader(train_dataset_voc_ext, batch_size=16, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_loader_voc_ext = DataLoader(valid_dataset_voc_ext, batch_size=16, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "18914551-6759-4d4d-9ff4-7bc6c2539124",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2e4c594f-19bc-4cf0-8219-2055e3dbaed0",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Defining a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1bba54ef-644f-4645-bcd4-4f4388b31ed6",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "class FocalTverskyLoss(torch.nn.Module):\n",
    "    __name__ = 'focal_tversky_loss'\n",
    "\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(FocalTverskyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1, alpha=0.7, beta=0.3, gamma=0.75):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = torch.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = (inputs * targets).sum()  \n",
    "        FP = ((1-targets) * inputs).sum()\n",
    "        FN = (targets * (1-inputs)).sum()\n",
    "        \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        FocalTversky = (1 - Tversky)**gamma\n",
    "        \n",
    "        return FocalTversky\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f67ba408-7111-4dd3-bf6f-574d337cd75b",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "# loss = smp.utils.losses.DiceLoss()\n",
    "\n",
    "ALPHA = 0.7\n",
    "BETA = 0.3\n",
    "GAMMA = 0.75\n",
    "\n",
    "loss1 = FocalTverskyLoss()\n",
    "loss2 = FocalTverskyLoss()\n",
    "loss3 = FocalTverskyLoss()\n",
    "loss4 = FocalTverskyLoss()\n",
    "\n",
    "metrics1 = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "metrics2 = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "metrics3 = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "metrics4 = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer1 = torch.optim.Adam([ \n",
    "    dict(params=models[\"mhp\"].parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "optimizer2 = torch.optim.Adam([ \n",
    "    dict(params=models[\"voc\"].parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "optimizer3 = torch.optim.Adam([ \n",
    "    dict(params=models[\"voc_orig\"].parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "optimizer4 = torch.optim.Adam([ \n",
    "    dict(params=models[\"voc_ext\"].parameters(), lr=0.0001),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ae36e75d-b467-45bb-9472-fe930f232506",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Create epoch runners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7751d522-e44e-4ae4-8a5d-6f998f86ea1f",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    models[\"mhp\"], \n",
    "    loss=loss1, \n",
    "    metrics=metrics1, \n",
    "    optimizer=optimizer1,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    models[\"mhp\"], \n",
    "    loss=loss1, \n",
    "    metrics=metrics1, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_epoch_voc = smp.utils.train.TrainEpoch(\n",
    "    models[\"voc\"], \n",
    "    loss=loss2, \n",
    "    metrics=metrics2, \n",
    "    optimizer=optimizer2,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch_voc = smp.utils.train.ValidEpoch(\n",
    "    models[\"voc\"], \n",
    "    loss=loss2, \n",
    "    metrics=metrics2, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_epoch_voc_orig = smp.utils.train.TrainEpoch(\n",
    "    models[\"voc_orig\"], \n",
    "    loss=loss3, \n",
    "    metrics=metrics3, \n",
    "    optimizer=optimizer3,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch_voc_orig = smp.utils.train.ValidEpoch(\n",
    "    models[\"voc_orig\"], \n",
    "    loss=loss3, \n",
    "    metrics=metrics3, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_epoch_voc_ext = smp.utils.train.TrainEpoch(\n",
    "    models[\"voc_ext\"], \n",
    "    loss=loss4, \n",
    "    metrics=metrics4, \n",
    "    optimizer=optimizer4,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch_voc_ext = smp.utils.train.ValidEpoch(\n",
    "    models[\"voc_ext\"], \n",
    "    loss=loss4, \n",
    "    metrics=metrics4, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "12af0298-a19d-42df-9391-06f167c3fc7a",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def run_epoch(train_epoch, valid_epoch, train_loader, valid_loader, name, max_scores):\n",
    "    print(name)\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    writer.add_scalar('{}/Loss/train'.format(name), train_logs[\"focal_tversky_loss\"], i)\n",
    "    writer.add_scalar('{}/IoU/train'.format(name), train_logs[\"iou_score\"], i)\n",
    "\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    writer.add_scalar('{}/Loss/valid'.format(name), valid_logs[\"focal_tversky_loss\"], i)\n",
    "    writer.add_scalar('{}/IoU/valid'.format(name), valid_logs[\"iou_score\"], i)\n",
    "        \n",
    "    if max_scores[name] < valid_logs['iou_score']:\n",
    "        max_scores[name] = valid_logs['iou_score']\n",
    "        torch.save(models[name], log_dir_name + '/best_model_{}.pth'.format(name))\n",
    "        print('{} Model saved!'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "876b5246-e82f-430b-8719-51f34a8c75da",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "max_scores = {\n",
    "    \"mhp\": 0,\n",
    "    \"voc\": 0,\n",
    "    \"voc_orig\": 0,\n",
    "    \"voc_ext\": 0\n",
    "}\n",
    "\n",
    "for i in range(0, 40):\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    \n",
    "    run_epoch(train_epoch, valid_epoch, train_loader, valid_loader, \"mhp\", max_scores)\n",
    "    run_epoch(train_epoch_voc, valid_epoch_voc, train_loader_voc, valid_loader_voc, \"voc\", max_scores)\n",
    "    run_epoch(train_epoch_voc_orig, valid_epoch_voc_orig, train_loader_voc_orig, valid_loader_voc_orig, \"voc_orig\", max_scores)    \n",
    "    run_epoch(train_epoch_voc_ext, valid_epoch_voc_ext, train_loader_voc_ext, valid_loader_voc_ext, \"voc_ext\", max_scores)\n",
    "    \n",
    "    if i == 25:\n",
    "        optimizer1.param_groups[0]['lr'] = 1e-5\n",
    "        optimizer2.param_groups[0]['lr'] = 1e-5\n",
    "        optimizer3.param_groups[0]['lr'] = 1e-5\n",
    "        optimizer4.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6dc6ad1a-aa91-4665-aeaa-1092678f4d6c",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "## Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "23d2b1a0-73a2-4679-8c5e-80a0fcf3c776",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "best_model = torch.load(log_dir_name + '/best_model_mhp.pth', map_location=DEVICE)\n",
    "best_model_voc = torch.load(log_dir_name + '/best_model_voc.pth', map_location=DEVICE)\n",
    "best_model_voc_orig = torch.load(log_dir_name + '/best_model_voc_orig.pth', map_location=DEVICE)\n",
    "best_model_voc_ext = torch.load(log_dir_name + '/best_model_voc_ext.pth', map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "03c91770-678f-43cb-a5d0-e49448bae79a",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "## test_dataset defined \"Load MHP Dataset\" section\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5ba19e77-8ad2-413f-bc1b-8f8ed68efdf0",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "class CustomValidEpoch(smp.utils.train.ValidEpoch):\n",
    "    def __init__(self, model, loss, metrics, device=DEVICE, verbose=True):\n",
    "         super().__init__(\n",
    "            model=model,\n",
    "            loss=loss,\n",
    "            metrics=metrics,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def batch_update(self, x, y):\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model.forward(x)  \n",
    "            argmax = torch.argmax(prediction, dim=1)\n",
    "            prediction = torch.where(argmax==15, 1, 0)\n",
    "            prediction = prediction[:, np.newaxis, :, :]\n",
    "            loss = self.loss(prediction, y)\n",
    "        return loss, prediction\n",
    "\n",
    "test_epoch = smp.utils.train.ValidEpoch(model=best_model, loss=loss1, metrics=metrics1, device=DEVICE)\n",
    "\n",
    "test_epoch_voc = smp.utils.train.ValidEpoch(model=best_model_voc, loss=loss2, metrics=metrics2, device=DEVICE)\n",
    "\n",
    "test_epoch_voc_orig = CustomValidEpoch(model=best_model_voc_orig, loss=loss3, metrics=metrics3, device=DEVICE)\n",
    "\n",
    "test_epoch_voc_ext = smp.utils.train.ValidEpoch(model=best_model_voc_ext, loss=loss4, metrics=metrics4, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7dc29dd0-0683-4eba-8a33-50b0efa2e2eb",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def run_test_epoch(epoch, dataloader, name):\n",
    "    print(name)\n",
    "    logs = epoch.run(dataloader)\n",
    "\n",
    "    writer.add_scalar('{}/Loss/test'.format(name), logs[\"focal_tversky_loss\"])\n",
    "    writer.add_scalar('{}/IoU/test'.format(name), logs[\"iou_score\"])\n",
    "\n",
    "run_test_epoch(test_epoch, test_dataloader, \"mhp\")\n",
    "run_test_epoch(test_epoch_voc, test_dataloader, \"voc\")\n",
    "run_test_epoch(test_epoch_voc_orig, test_dataloader, \"voc_orig\")\n",
    "run_test_epoch(test_epoch_voc_ext, test_dataloader, \"voc_ext\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "393ce3a1-b823-4052-a67a-9983a23507ef",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "### Inference Time Measurement\n",
    "https://deci.ai/resources/blog/measure-inference-time-deep-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bed1517e-2f93-4d53-bb8d-43c1c50fe521",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "def measureInferenceTime(model, dataset):\n",
    "    model.to(DEVICE)\n",
    "    repetitions= 100\n",
    "    total_time = 0\n",
    "    with torch.no_grad():\n",
    "        for rep in tqdm(range(repetitions)):\n",
    "            n = np.random.choice(len(dataset))\n",
    "            image, _ = dataset[n]\n",
    "            x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "            start = timer()\n",
    "            _ = best_model.predict(x_tensor)\n",
    "            end = timer()\n",
    "            elapsed_time = (end-start)/1000\n",
    "            total_time += elapsed_time\n",
    "    inference_time = total_time/repetitions\n",
    "    print('Average inference time:', inference_time)\n",
    "    return inference_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "90eaf6d8-8810-4279-b6ea-65dc18f30ad7",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "# MHP Model \n",
    "time = measureInferenceTime(best_model, test_dataset)\n",
    "writer.add_scalar('mhp/time', time)\n",
    "# VOC Model\n",
    "time = measureInferenceTime(best_model_voc, test_dataset)\n",
    "writer.add_scalar('voc/time', time)\n",
    "# VOC Orig Model\n",
    "time = measureInferenceTime(best_model_voc_orig, test_dataset)\n",
    "writer.add_scalar('voc_orig/time', time)\n",
    "# VOC Orig Model\n",
    "time = measureInferenceTime(best_model_voc_ext, test_dataset)\n",
    "writer.add_scalar('voc_ext/time', time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4437ccc0-ecf3-4252-89b7-ed05d18583cc",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "11bb1b26-3f17-4b8f-bfaf-3fae379fe5ce",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "# test dataset without transformations for image visualization\n",
    "test_dataset_vis = Dataset(\n",
    "    size=1000,\n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "1bbb718c-4611-474b-8111-6623305c7b0b",
     "kernelId": "709bc842-7e85-4e5e-9216-b915878d5888"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    n = np.random.choice(len(test_dataset))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "    image, gt_mask = test_dataset[n]\n",
    "    \n",
    "    gt_mask = gt_mask.squeeze()\n",
    "\n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    \n",
    "    pr_mask = best_model.predict(x_tensor)\n",
    "    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "\n",
    "    pr_mask_voc = best_model_voc.predict(x_tensor)\n",
    "    pr_mask_voc = (pr_mask_voc.squeeze().cpu().numpy().round())\n",
    "\n",
    "    pr_mask_voc_orig = best_model_voc_orig.predict(x_tensor)\n",
    "    argmax = torch.argmax(pr_mask_voc_orig, dim=1)\n",
    "    pr_mask_voc_orig = torch.where(argmax==15, 1, 0)\n",
    "    pr_mask_voc_orig = pr_mask_voc_orig[:, np.newaxis, :, :]\n",
    "    pr_mask_voc_orig = (pr_mask_voc_orig.squeeze().cpu().numpy().round())\n",
    "        \n",
    "    visualize(\n",
    "        image=image_vis, \n",
    "        ground_truth_mask=gt_mask, \n",
    "        predicted_mask=pr_mask,\n",
    "        predicted_mask_voc=pr_mask_voc,\n",
    "        predicted_mask_voc_orig=pr_mask_voc_orig,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74022aae890ba747b3a4262e7e8e47cd7ef92a3925bdc86f96fbcbbd0ea6874b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
